receiver方式整合：
1) 启动zk  cd $ZK_HOME/bin  ./zkServer.sh start
2) 启动kafka 到kafka的bin目录下，
./kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties
3) 创建topic
./kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1
--partitions 1 --topic kafka_streaming_kobekun_topic
4) 查询topic
./kafka-topics.sh --list --zookeeper localhost:2181
5) 通过控制台测试topic是否能够正常的生产和消费信息
./kafka-console-producer.sh --broker-list localhost:9092 --topic kafka_streaming_kobekun_topic
./kafka-console-consumer.sh --zookeeper localhost:2181 --topic kafka_streaming_kobekun_topic

提交
spark-submit \
--class com.kobekun.spark.KafkaReceiverWordCount \
--master local[2] \
--name KafkaReceiverWordCount \
--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.2.0 \
/home/hadoop/app/submit/sparkStreaming-1.0-SNAPSHOT.jar hadoop000:2181 test kafka_streaming_kobekun_topic 1